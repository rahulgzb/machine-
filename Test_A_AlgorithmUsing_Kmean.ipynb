{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbf305d",
   "metadata": {},
   "source": [
    "# Performing TEST-A algorithm using K-mean clustering algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29410609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing basic modules for implementation of k-means\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#importing modules of sklearn for measuring performance of K-mean\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa205ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    t_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    first_df = df.loc[t_indices]\n",
    "    second_df = df.drop(t_indices)\n",
    "    \n",
    "    return first_df, second_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808d7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method that is used for calculating the eculidean distance between two data points\n",
    "def euclidean_distance(x1,x2):\n",
    "        res=np.sum((x1-x2)**2)\n",
    "        return math.sqrt(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5e909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a class for kmeans\n",
    "class Kmeans:\n",
    "    #constructor of the class Kmeans\n",
    "    def __init__(self,K,max_iteration):\n",
    "        self.K=K\n",
    "        self.max_iteration=max_iteration\n",
    "        self.clusters=[[] for _ in range(self.K)]\n",
    "        self.centroids=[]  \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This method performs the following things--\n",
    "       1.Finds the total number of samples and total features from the Data Set X\n",
    "       2.Choose the K random indices from the samples.\n",
    "       3.After that we access the K random samples using these K Random indices.\n",
    "         These K random samples will be our initial Centroids.\n",
    "       4.We ran a loop to check the convergernce of the algorithm.\n",
    "         If it is converges then we break and return cluster labels assigned to data points.\n",
    "    \"\"\"  \n",
    "    def predict(self,X,clusterData):\n",
    "        self.X=X\n",
    "        self.no_samples,self.no_features=X.shape\n",
    "        self.centroids=clusterData\n",
    "        for _ in range(self.max_iteration):\n",
    "            self.clusters=self.createClusters(self.centroids)\n",
    "            oldCentroids=self.centroids\n",
    "            self.centroids=self.getCentroids(self.clusters)\n",
    "            \n",
    "            if self.isConverge(oldCentroids,self.centroids):\n",
    "                break  \n",
    "        labels=self.getClusterLabels(self.clusters)\n",
    "        return oldCentroids\n",
    "    \n",
    "    # method is used for finding cluster for each data points in X\n",
    "    def createClusters(self,centroids):\n",
    "        clusters=[[] for _ in range(self.K)]\n",
    "        for i,data in enumerate(self.X):\n",
    "            centroid_index=self.closestCentroid(data,centroids)\n",
    "            clusters[centroid_index].append(i)\n",
    "        \n",
    "        return clusters\n",
    "    \n",
    "    # method is used for finding the closer centroid for a particular given data\n",
    "    def closestCentroid(self,data,centroids):\n",
    "        d=[euclidean_distance(data,k) for k in centroids]\n",
    "        closeIndex=np.argmin(d)\n",
    "        return closeIndex\n",
    "    \n",
    "    \n",
    "    #when all data points assigned to diffrent clusters then we have to update the centroids points by taking mean \n",
    "    #this method is used for that purpose\n",
    "    \n",
    "    def getCentroids(self,clusters):\n",
    "        centroids=np.zeros((self.K,self.no_features))\n",
    "        \n",
    "        for clus_index,clus_data in enumerate(clusters):\n",
    "            clus_mean=np.mean(self.X[clus_data],axis=0)\n",
    "            centroids[clus_index]=clus_mean\n",
    "        \n",
    "        return centroids\n",
    "    \n",
    "    #this method returns the cluster labels assigned to diffrent datapoints and it returns a list\n",
    "    def getClusterLabels(self,clusters):\n",
    "        label=np.empty(self.no_samples)\n",
    "        for clus_index,clus_data in enumerate(clusters):\n",
    "            for k in clus_data:\n",
    "                label[k]=clus_index \n",
    "        return label\n",
    "    \n",
    "    #this method check whether old centroids gets updated or not\n",
    "    def isConverge(self,oldCentroids,centroids):\n",
    "        d=[euclidean_distance(oldCentroids[i],centroids[i]) for i in range(self.K)]\n",
    "        if sum(d)==0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2510283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestCluster(data,centroids):\n",
    "    d=[euclidean_distance(data,k) for k in centroids]\n",
    "    closeIndex=np.argmin(d)\n",
    "    return closeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91e3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(\"bupa.txt\") \n",
    "    \n",
    "    Avg_NMI_Scores=[]\n",
    "    for i in range(50):\n",
    "        cluster_df,NonCluster_df=data_split(df,2)\n",
    "        cluster_df=cluster_df[[\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",\"drinks\"]]\n",
    "        clusterData=cluster_df.to_numpy()\n",
    "        sum1=0.0\n",
    "        for k in range(50):\n",
    "            test_df,train_df=data_split(NonCluster_df,0.2)\n",
    "            train_df=train_df[[\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",\"drinks\"]]\n",
    "            test_data_original_label=test_df[\"selector\"].tolist()\n",
    "            X=train_df.to_numpy()\n",
    "        \n",
    "            k=Kmeans(2,50)\n",
    "            centroids=k.predict(X,clusterData)\n",
    "            test_data_pred_label=[]\n",
    "            test_df=test_df[[\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",\"drinks\"]]\n",
    "            Y=test_df.to_numpy()\n",
    "            for data in Y:\n",
    "                cluster_index=closestCluster(data,centroids)\n",
    "                test_data_pred_label.append(cluster_index+1)\n",
    "            nmi_score=metrics.normalized_mutual_info_score(test_data_original_label,test_data_pred_label)\n",
    "            sum1=sum1+nmi_score\n",
    "        \n",
    "        avg_nmi=sum1/50\n",
    "        print(\"Iteration\",i+1,\" -->NMI Score\",avg_nmi)\n",
    "        Avg_NMI_Scores.append(avg_nmi)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e05794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 -->NMI Score 0.018216892943561425\n",
      "Iteration 2 -->NMI Score 0.019694280116679404\n",
      "Iteration 3 -->NMI Score 0.011458887857960896\n",
      "Iteration 4 -->NMI Score 0.01685424959775059\n",
      "Iteration 5 -->NMI Score 0.015622476695916916\n",
      "Iteration 6 -->NMI Score 0.014605551934256117\n",
      "Iteration 7 -->NMI Score 0.008989496522803012\n",
      "Iteration 8 -->NMI Score 0.017877209459709522\n",
      "Iteration 9 -->NMI Score 0.006476787447877757\n",
      "Iteration 10 -->NMI Score 0.010307484999768001\n",
      "Iteration 11 -->NMI Score 0.010927687659017702\n",
      "Iteration 12 -->NMI Score 0.013010565507826685\n",
      "Iteration 13 -->NMI Score 0.01674669214248877\n",
      "Iteration 14 -->NMI Score 0.010268768793368183\n",
      "Iteration 15 -->NMI Score 0.009425670744025654\n",
      "Iteration 16 -->NMI Score 0.018049944940081764\n",
      "Iteration 17 -->NMI Score 0.017186071723875894\n",
      "Iteration 18 -->NMI Score 0.013155644661519339\n",
      "Iteration 19 -->NMI Score 0.016822583571809647\n",
      "Iteration 20 -->NMI Score 0.01240309387114009\n",
      "Iteration 21 -->NMI Score 0.012259510260230288\n",
      "Iteration 22 -->NMI Score 0.011634761538427059\n",
      "Iteration 23 -->NMI Score 0.014154165520385835\n",
      "Iteration 24 -->NMI Score 0.011499786485513992\n",
      "Iteration 25 -->NMI Score 0.021958896801192326\n",
      "Iteration 26 -->NMI Score 0.013668292117653753\n",
      "Iteration 27 -->NMI Score 0.012763091864799979\n",
      "Iteration 28 -->NMI Score 0.015234678362495386\n",
      "Iteration 29 -->NMI Score 0.015868389596738877\n",
      "Iteration 30 -->NMI Score 0.012481767288620063\n",
      "Iteration 31 -->NMI Score 0.01619955927956005\n",
      "Iteration 32 -->NMI Score 0.010208509642997379\n",
      "Iteration 33 -->NMI Score 0.013957532244173726\n",
      "Iteration 34 -->NMI Score 0.015890621635335278\n",
      "Iteration 35 -->NMI Score 0.01011590663340501\n",
      "Iteration 36 -->NMI Score 0.014363247024737654\n",
      "Iteration 37 -->NMI Score 0.01509596119103662\n",
      "Iteration 38 -->NMI Score 0.019564251401744514\n",
      "Iteration 39 -->NMI Score 0.01191787745007743\n",
      "Iteration 40 -->NMI Score 0.011845428744280781\n",
      "Iteration 41 -->NMI Score 0.015035646570966827\n",
      "Iteration 42 -->NMI Score 0.017290679657391717\n",
      "Iteration 43 -->NMI Score 0.019976904001434134\n",
      "Iteration 44 -->NMI Score 0.014642807105133236\n",
      "Iteration 45 -->NMI Score 0.017623796034026404\n",
      "Iteration 46 -->NMI Score 0.009878874788572155\n",
      "Iteration 47 -->NMI Score 0.016393826547068408\n",
      "Iteration 48 -->NMI Score 0.01431180250367362\n",
      "Iteration 49 -->NMI Score 0.019683466908630664\n",
      "Iteration 50 -->NMI Score 0.016796866681485403\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
